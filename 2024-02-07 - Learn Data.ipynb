{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only change folder_path\n",
    "folder_path = r\"C:\\Users\\Nikolai\\Downloads\\archive\"\n",
    "\n",
    "symbol_path = os.path.join(folder_path, \"symbols_valid_meta.csv\")\n",
    "stocks_folder = os.path.join(folder_path, \"stocks\")\n",
    "etfs_folder = os.path.join(folder_path, \"etfs\")\n",
    "\n",
    "# Load data\n",
    "symbols = pd.read_csv(symbol_path)\n",
    "\n",
    "# More info about the columns- https://www.nasdaqtrader.com/trader.aspx?id=symboldirdefs\n",
    "symbols.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = symbols[\"ETF\"] == \"Y\"\n",
    "\n",
    "# Get only Exchange-Traded Funds\n",
    "etfs = symbols.loc[query].reset_index(drop=True).copy()\n",
    "# Get only Stocks\n",
    "stocks = symbols.loc[~query].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocks that we will work with are here\n",
    "# NOTE: \"Common Stock\" means that a stock can be bought or sold by investors or traders\n",
    "my_securities = {\n",
    "    \"MSFT\": \"Microsoft Corporation - Common Stock\",\n",
    "    \"AAPL\": \"Apple Inc. - Common Stock\",\n",
    "    \"NVDA\": \"NVIDIA Corporation - Common Stock\",\n",
    "    \"TSLA\": \"Tesla, Inc. - Common Stock\",\n",
    "    \"AMZN\": \"Amazon.com, Inc. - Common Stock\",\n",
    "    \"NFLX\": \"Netflix, Inc. - Common Stock\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = list(my_securities.keys())\n",
    "# Randomly pick a symbol\n",
    "demo = random.choice(stock_symbols)\n",
    "\n",
    "# NOTE: the files' names are based on the symbol name\n",
    "file_path = os.path.join(stocks_folder, f\"{demo}.csv\")\n",
    "data = pd.read_csv(file_path)\n",
    "data[\"symbol\"] = demo\n",
    "\n",
    "# Change data type\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "\n",
    "print(f\"Loaded data for {demo}\")\n",
    "# Overall information about the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = data[[\"Date\", \"symbol\", \"Adj Close\"]].copy()\n",
    "stats.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate period returns - the percent change (decimals) on a daily basis\n",
    "# NOTE: to get the PERCENTAGES (%) you need to multiply the column by 100\n",
    "stats[\"1day\"] = stats[\"Adj Close\"].pct_change().fillna(0)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(data: pd.DataFrame, calculation_period: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate the month to date (mtd) / year to date (ytd) / inception to date (itd)\n",
    "\n",
    "    Parameters:\n",
    "        - data - the raw data\n",
    "        - calculation_period - the period to calculate the data for.\n",
    "                               The available options are - mtd, qtd, ytd, itd\n",
    "\n",
    "    Output:\n",
    "        - Either the mtd, qtd, ytd or itd column depending on the selected\n",
    "          calculation_period. The numbers are on a daily basis.\n",
    "    \"\"\"\n",
    "    stats = data.copy()\n",
    "    calculation_period = calculation_period.lower()\n",
    "\n",
    "    period_map = {\n",
    "        \"mtd\": \"M\",\n",
    "        \"qtd\": \"Q\",\n",
    "        \"ytd\": \"Y\",\n",
    "        \"itd\": None\n",
    "    }\n",
    "\n",
    "    # Stop the program\n",
    "    if calculation_period not in period_map.keys(): return\n",
    "\n",
    "    selected_period = period_map[calculation_period]\n",
    "\n",
    "    if not selected_period:\n",
    "        # ITD\n",
    "        for date in stats[\"Date\"].tolist():\n",
    "            query = stats[\"Date\"] <= date\n",
    "            calculation = (stats.loc[query, \"1day\"] + 1).product() - 1\n",
    "            \n",
    "            query = stats[\"Date\"] == date\n",
    "            stats.loc[query, calculation_period] = calculation\n",
    "        \n",
    "        return stats[calculation_period].copy()\n",
    "\n",
    "    # MTD / YTD\n",
    "    stats[\"period\"] = stats[\"Date\"].dt.to_period(selected_period)\n",
    "\n",
    "    for period, group in stats.groupby(\"period\"):\n",
    "        for date in group[\"Date\"].tolist():\n",
    "            query = (stats[\"period\"] == period) & (stats[\"Date\"] <= date)\n",
    "            calculation = (stats.loc[query, \"1day\"] + 1).product() - 1\n",
    "            \n",
    "            query = (stats[\"period\"] == period) & (stats[\"Date\"] == date)\n",
    "            stats.loc[query, calculation_period] = calculation\n",
    "\n",
    "    return stats[calculation_period].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats.assign(\n",
    "    mtd = calculate_returns(stats, \"mtd\"), # Month to date\n",
    "    qtd = calculate_returns(stats, \"qtd\"), # Quarter to date\n",
    "    ytd = calculate_returns(stats, \"ytd\"), # Year to date\n",
    "    itd = calculate_returns(stats, \"itd\"), # Inception to date\n",
    ")\n",
    "\n",
    "stats.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Month to Date only\n",
    "stats.assign(period = stats[\"Date\"].dt.to_period(\"M\"))\\\n",
    "     .drop_duplicates(\"period\", keep=\"last\")\\\n",
    "     .drop(labels=[\"1day\", \"qtd\", \"ytd\", \"itd\", \"period\", \"Adj Close\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Annual Return](https://www.investopedia.com/terms/a/annual-return.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_return(daily_returns: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the annual return\n",
    "\n",
    "    Parameters:\n",
    "        - daily_returns - the percent change column on a daily basis (1day)\n",
    "\n",
    "    Ouput:\n",
    "        - the annual return\n",
    "    \"\"\"\n",
    "    returns = daily_returns.copy()\n",
    "    return (((returns + 1).product() - 1) ** (252 / (returns.shape[0] - 1))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = round(annual_return(stats[\"1day\"]) * 100, 2)\n",
    "print(f\"{demo} generates {percent}% annually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Volatility](https://www.investopedia.com/terms/v/volatility.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatility(daily_returns: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the stock volatility\n",
    "\n",
    "    Parameters:\n",
    "        - daily_returns - the percent change column on a daily basis (1day)\n",
    "\n",
    "    Ouput:\n",
    "        - the volatility\n",
    "    \"\"\"\n",
    "    returns = daily_returns.copy()\n",
    "\n",
    "    return np.std(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = round(volatility(stats[\"1day\"]) * 100, 2)\n",
    "print(f\"{demo}'s volatility is {percent}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Candlestick](https://www.investopedia.com/terms/c/candlestick.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candlestick = go.Candlestick(x=viz_data[\"Date\"], open=viz_data[\"Open\"], high=viz_data[\"High\"], low=viz_data[\"Low\"], close=viz_data[\"Close\"], name=\"Candle\")\n",
    "fig = go.Figure(data = [candlestick])\n",
    "\n",
    "# Update the plot layout\n",
    "fig.update_layout(title=my_securities[demo], yaxis_title=\"Price\", hovermode = \"x unified\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Moving Average](https://www.investopedia.com/terms/m/movingaverage.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 day moving average\n",
    "viz_data[\"50 MA\"] = viz_data[\"Adj Close\"].rolling(50).mean()\n",
    "\n",
    "# 100 day moving average\n",
    "viz_data[\"100 MA\"] = viz_data[\"Adj Close\"].rolling(100).mean()\n",
    "\n",
    "# 200 day moving average\n",
    "viz_data[\"200 MA\"] = viz_data[\"Adj Close\"].rolling(200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [candlestick])\n",
    "\n",
    "# Moving average for 50 days\n",
    "moving_avg_50 = go.Scatter(x = viz_data[\"Date\"], y = viz_data[\"50 MA\"], line_color = \"black\", name = \"Moving Avg. 50\", opacity=0.5)\n",
    "fig.add_trace(moving_avg_50)\n",
    "\n",
    "# Moving average for 100 days\n",
    "moving_avg_50 = go.Scatter(x = viz_data[\"Date\"], y = viz_data[\"100 MA\"], line_color = \"red\", name = \"Moving Avg. 100\", opacity=0.5)\n",
    "fig.add_trace(moving_avg_50)\n",
    "\n",
    "# Moving average for 200 days\n",
    "moving_avg_50 = go.Scatter(x = viz_data[\"Date\"], y = viz_data[\"200 MA\"], line_color = \"green\", name = \"Moving Avg. 200\", opacity=0.5)\n",
    "fig.add_trace(moving_avg_50)\n",
    "\n",
    "fig.update_layout(hovermode = \"x unified\", title_text = f\"Moving Average for 50, 100 and 200 period\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Double Bollinger Bands](https://www.investopedia.com/terms/b/bollingerbands.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = viz_data[\"Adj Close\"].rolling(20).mean()\n",
    "std = viz_data[\"Adj Close\"].rolling(20).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [candlestick])\n",
    "\n",
    "# Upper Bollinger Band\n",
    "upper_band = go.Scatter(x = viz_data[\"Date\"], y = (moving_avg + (std * 2)), line_color = \"black\", name = \"Upper Band\", opacity=0.5, line = {\"dash\": \"dash\"})\n",
    "fig.add_trace(upper_band)\n",
    "\n",
    "# Lower Bollinger Band\n",
    "lower_band = go.Scatter(x = viz_data[\"Date\"], y = (moving_avg - (std * 2)), line_color = \"black\", name = \"Upper Band\", opacity=0.5, line = {\"dash\": \"dash\"})\n",
    "fig.add_trace(lower_band)\n",
    "\n",
    "fig.update_layout(hovermode = \"x unified\", title_text = f\"Double Bollinger Bands\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [S&P 500 Components](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the S&P 500 Components from website\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "html = BeautifulSoup(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape table into HTML\n",
    "columns = []\n",
    "table_data = []\n",
    "\n",
    "for table_row in html.find(id=\"constituents\").find_all(\"tr\"):\n",
    "\n",
    "    # First row is always the header\n",
    "    if not columns:\n",
    "        columns = [th.text.strip().lower().replace(\" \", \"-\").replace(\"-\", \"_\") for th in table_row.find_all(\"th\")]\n",
    "        continue\n",
    "    \n",
    "    # Second row onwards has the data\n",
    "    raw_data = [td.text.strip() for td in table_row.find_all(\"td\")]\n",
    "\n",
    "    # dictionary format - column: value\n",
    "    table_data.append(dict(zip(columns, raw_data)))\n",
    "\n",
    "data = pd.DataFrame(table_data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix columns\n",
    "data = data.assign(\n",
    "    # Keep the first date from left to right\n",
    "    founded = data[\"founded\"].str.split(\" \").str[0].str.split(\"/\").str[0].astype(int),\n",
    "    date_added = pd.to_datetime(data[\"date_added\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = data.assign(count = 1).groupby(\"gics_sector\").sum(numeric_only=True).drop(\"founded\", axis=1).reset_index().copy()\n",
    "\n",
    "fig = px.pie(sectors, values=\"count\", names=\"gics_sector\", title=\"S&P 500 Sectors\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get company weights\n",
    "\n",
    "# Change this path\n",
    "html_path = r\"C:\\Users\\Nikolai\\Downloads\\archive\\S&P 500 Companies by Weight.html\"\n",
    "html = BeautifulSoup(open(html_path).read(), \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "table_data = []\n",
    "\n",
    "for table_row in html.find(\"table\", class_=\"table table-hover table-borderless table-sm\").find_all(\"tr\"):\n",
    "\n",
    "    if not columns:\n",
    "        columns = [th.text.strip() for th in table_row.find_all(\"th\")]\n",
    "        continue\n",
    "    \n",
    "    # Second row onwards has the data\n",
    "    raw_data = [td.text.strip() for td in table_row.find_all(\"td\")]\n",
    "\n",
    "    # dictionary format - column: value\n",
    "    table_data.append(dict(zip(columns, raw_data)))\n",
    "\n",
    "name_mappings = {\n",
    "    \"Symbol\": \"symbol\",\n",
    "    \"Portfolio%\": \"weight\"\n",
    "}\n",
    "weights = pd.DataFrame(table_data)[list(name_mappings.keys())].rename(columns=name_mappings)\n",
    "\n",
    "weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the weights to the Wikipedia data\n",
    "data = data.merge(weights, how=\"left\", on=\"symbol\")\n",
    "# Convert weights to decimal floats\n",
    "data[\"weight\"] = data[\"weight\"].str.replace(\"%\", \"\").astype(float) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = data.groupby(\"gics_sector\").sum(numeric_only=True).drop(\"founded\", axis=1).reset_index().copy()\n",
    "\n",
    "fig = px.pie(sectors, values=\"weight\", names=\"gics_sector\", title=\"S&P 500 Components weight\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the countries\n",
    "data[\"country\"] = data[\"headquarters_location\"].str.split(\", \").str[1]\n",
    "\n",
    "country_code_url = \"https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv\"\n",
    "country_codes = pd.read_csv(country_code_url)\n",
    "\n",
    "# Make columns lowercase\n",
    "country_codes.columns = [column.lower() for column in country_codes.columns]\n",
    "data = data.merge(country_codes, how=\"left\", on=\"country\").drop(\"gdp (billions)\", axis=1)\n",
    "\n",
    "# NOTE: UK and US states are missing countries\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Missing codes are based on the country_codes variable\n",
    "\n",
    "# Fills missing codes with USA\n",
    "data[\"code\"] = data[\"code\"].fillna(\"USA\")\n",
    "\n",
    "# Fix the UK\n",
    "data.loc[data[\"country\"] == \"UK\", \"code\"] = \"GBR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_map_data = data.groupby(\"code\").sum(numeric_only=True).drop(\"founded\", axis=1).sort_values(\"weight\").reset_index().copy()\n",
    "\n",
    "# Visualize world map\n",
    "world_map = go.Choropleth(\n",
    "        locations = world_map_data['code'],\n",
    "        z = (world_map_data['weight'] * 100).round(2),\n",
    "        colorscale = 'Reds',\n",
    "        marker_line_width=0.5,\n",
    "        colorbar_title = 'Weights',\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=world_map)\n",
    "fig.update_layout(\n",
    "    title_text='S&P 500 Country Weights',\n",
    "    geo=dict(showframe=False, showcoastlines=False,),\n",
    "    annotations = [dict(showarrow = False, text='')]\n",
    ")\n",
    "  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same numbers as the map\n",
    "world_map_data.assign(weight= (world_map_data[\"weight\"] * 100).round(2))\\\n",
    "            .sort_values(\"weight\", ascending=False)\\\n",
    "            .reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
